# Persistence Specification (1.2.2)

**Version:** 1.0
**Date:** September 16, 2025
**Status:** Draft
**Phase:** 1.2 - State Management (Simplified MVP)

## Overview

This specification defines the persistence layer for RAG Studio's MVP implementation. The design uses basic SQLite storage with async operations, following a simple load-on-startup and periodic save pattern, with clear upgrade path to event sourcing post-MVP.

## Architecture Decision

### MVP Approach: Single Database with Periodic Persistence
- **Pattern**: Single app_meta.db with periodic saves and load-on-startup
- **Rationale**: Simple to implement, sufficient for MVP scale, proven approach
- **Upgrade Path**: Split to events.db for event sourcing, add WAL mode, implement event replay
- **Trade-offs**: Less real-time than continuous persistence but simpler and more reliable

## Database Schema

### Core Tables Structure

```sql
-- Migration: 001_initial_schema.sql

-- Application metadata
CREATE TABLE app_settings (
    key TEXT PRIMARY KEY,
    value TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Tools registry (FR-1)
CREATE TABLE tools (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    description TEXT,
    schema_json TEXT NOT NULL, -- JSON schema
    endpoint_config TEXT NOT NULL, -- JSON config
    status TEXT NOT NULL CHECK (status IN ('active', 'inactive', 'error')),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Knowledge bases (FR-2)
CREATE TABLE knowledge_bases (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    version TEXT NOT NULL,
    description TEXT,
    status TEXT NOT NULL CHECK (status IN ('active', 'building', 'error', 'archived')),
    health TEXT NOT NULL CHECK (health IN ('healthy', 'degraded', 'unhealthy')),
    metadata_json TEXT NOT NULL, -- KbMetadata as JSON
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(name, version)
);

-- Pipeline definitions (FR-3)
CREATE TABLE pipelines (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    description TEXT,
    steps_json TEXT NOT NULL, -- Vec<PipelineStep> as JSON
    config_json TEXT NOT NULL, -- PipelineConfig as JSON
    status TEXT NOT NULL CHECK (status IN ('active', 'inactive', 'error')),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Pipeline runs (FR-3.4)
CREATE TABLE pipeline_runs (
    id TEXT PRIMARY KEY,
    pipeline_id TEXT NOT NULL REFERENCES pipelines(id) ON DELETE CASCADE,
    status TEXT NOT NULL CHECK (status IN ('pending', 'running', 'completed', 'failed', 'cancelled')),
    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP,
    metrics_json TEXT, -- RunMetrics as JSON
    error_message TEXT,
    INDEX idx_pipeline_runs_pipeline_id (pipeline_id),
    INDEX idx_pipeline_runs_status (status),
    INDEX idx_pipeline_runs_started_at (started_at)
);

-- Schedules (FR-4)
CREATE TABLE schedules (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    pipeline_id TEXT NOT NULL REFERENCES pipelines(id) ON DELETE CASCADE,
    cron_expression TEXT NOT NULL,
    enabled BOOLEAN NOT NULL DEFAULT TRUE,
    next_run TIMESTAMP,
    last_run TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_schedules_pipeline_id (pipeline_id),
    INDEX idx_schedules_enabled_next_run (enabled, next_run)
);

-- Flows (FR-6)
CREATE TABLE flows (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    description TEXT,
    steps_json TEXT NOT NULL, -- Vec<FlowStep> as JSON
    checksum TEXT NOT NULL, -- SHA-256 checksum for validation
    status TEXT NOT NULL CHECK (status IN ('active', 'inactive', 'error')),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Performance metrics (FR-8) - Aggregated storage
CREATE TABLE metrics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    value REAL NOT NULL,
    labels_json TEXT, -- HashMap<String, String> as JSON
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_metrics_name_timestamp (name, timestamp),
    INDEX idx_metrics_timestamp (timestamp)
);

-- Critical events (FR-8, FR-9) - Preparation for event sourcing
CREATE TABLE events (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    event_type TEXT NOT NULL,
    component TEXT NOT NULL,
    event_data TEXT NOT NULL, -- JSON payload
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_events_component_timestamp (component, timestamp),
    INDEX idx_events_type_timestamp (event_type, timestamp)
);

-- Error tracking (FR-11)
CREATE TABLE errors (
    id TEXT PRIMARY KEY,
    component TEXT NOT NULL,
    error_type TEXT NOT NULL,
    message TEXT NOT NULL,
    recoverable BOOLEAN NOT NULL DEFAULT TRUE,
    resolved BOOLEAN NOT NULL DEFAULT FALSE,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    resolved_at TIMESTAMP,
    INDEX idx_errors_component_resolved (component, resolved),
    INDEX idx_errors_timestamp (timestamp)
);
```

### Indexes and Constraints

```sql
-- Migration: 002_indexes.sql

-- Performance indexes for common queries
CREATE INDEX idx_knowledge_bases_status ON knowledge_bases(status);
CREATE INDEX idx_knowledge_bases_name ON knowledge_bases(name);
CREATE INDEX idx_tools_status ON tools(status);
CREATE INDEX idx_flows_status ON flows(status);

-- Foreign key constraints
PRAGMA foreign_keys = ON;
```

## Persistence Service Implementation

### Service Interface

```rust
use async_trait::async_trait;
use diesel::prelude::*;
use diesel::sqlite::SqliteConnection;
use diesel_async::{AsyncConnection, AsyncSqliteConnection};
use std::collections::HashMap;

#[async_trait]
pub trait PersistenceService: Send + Sync {
    // Load operations
    async fn load_app_state(&self) -> Result<AppState, PersistenceError>;
    async fn load_settings(&self) -> Result<AppSettings, PersistenceError>;

    // Save operations
    async fn save_app_state(&self, state: &AppState) -> Result<(), PersistenceError>;
    async fn save_settings(&self, settings: &AppSettings) -> Result<(), PersistenceError>;

    // Individual entity operations
    async fn save_tool(&self, tool: &Tool) -> Result<(), PersistenceError>;
    async fn save_kb(&self, kb: &KnowledgeBase) -> Result<(), PersistenceError>;
    async fn save_pipeline(&self, pipeline: &Pipeline) -> Result<(), PersistenceError>;
    async fn save_pipeline_run(&self, run: &PipelineRun) -> Result<(), PersistenceError>;
    async fn save_schedule(&self, schedule: &Schedule) -> Result<(), PersistenceError>;
    async fn save_flow(&self, flow: &Flow) -> Result<(), PersistenceError>;

    // Delete operations
    async fn delete_tool(&self, id: &str) -> Result<(), PersistenceError>;
    async fn delete_kb(&self, id: &str) -> Result<(), PersistenceError>;
    async fn delete_pipeline(&self, id: &str) -> Result<(), PersistenceError>;
    async fn delete_schedule(&self, id: &str) -> Result<(), PersistenceError>;
    async fn delete_flow(&self, id: &str) -> Result<(), PersistenceError>;

    // Metrics and events
    async fn save_metric(&self, metric: &MetricValue) -> Result<(), PersistenceError>;
    async fn save_event(&self, event: &PersistenceEvent) -> Result<(), PersistenceError>;
    async fn save_error(&self, error: &AppError) -> Result<(), PersistenceError>;

    // Cleanup operations
    async fn cleanup_old_metrics(&self, older_than: chrono::DateTime<chrono::Utc>) -> Result<(), PersistenceError>;
    async fn cleanup_completed_runs(&self, older_than: chrono::DateTime<chrono::Utc>) -> Result<(), PersistenceError>;
    async fn cleanup_resolved_errors(&self, older_than: chrono::DateTime<chrono::Utc>) -> Result<(), PersistenceError>;
}

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct PersistenceEvent {
    pub event_type: String,
    pub component: String,
    pub event_data: serde_json::Value,
    pub timestamp: chrono::DateTime<chrono::Utc>,
}

#[derive(Debug, thiserror::Error)]
pub enum PersistenceError {
    #[error("Database connection error: {0}")]
    ConnectionError(#[from] diesel::result::Error),

    #[error("Serialization error: {0}")]
    SerializationError(#[from] serde_json::Error),

    #[error("Migration error: {0}")]
    MigrationError(String),

    #[error("Data integrity error: {0}")]
    IntegrityError(String),

    #[error("Not found: {0}")]
    NotFound(String),
}
```

### SQLite Implementation

```rust
use diesel::connection::SimpleConnection;
use diesel_async::pooled_connection::AsyncDieselConnectionManager;
use diesel_migrations::{embed_migrations, EmbeddedMigrations, MigrationHarness};

pub const MIGRATIONS: EmbeddedMigrations = embed_migrations!("migrations/");

pub struct SqlitePersistenceService {
    pool: bb8::Pool<AsyncDieselConnectionManager<AsyncSqliteConnection>>,
}

impl SqlitePersistenceService {
    pub async fn new(database_url: &str) -> Result<Self, PersistenceError> {
        // Create connection manager
        let manager = AsyncDieselConnectionManager::<AsyncSqliteConnection>::new(database_url);

        // Create connection pool
        let pool = bb8::Pool::builder()
            .max_size(10)
            .connection_timeout(std::time::Duration::from_secs(30))
            .build(manager)
            .await
            .map_err(|e| PersistenceError::ConnectionError(diesel::result::Error::DatabaseError(
                diesel::result::DatabaseErrorKind::__Unknown,
                Box::new(format!("Pool creation failed: {}", e))
            )))?;

        // Run migrations
        let mut conn = diesel::sqlite::SqliteConnection::establish(database_url)
            .map_err(PersistenceError::ConnectionError)?;

        conn.run_pending_migrations(MIGRATIONS)
            .map_err(|e| PersistenceError::MigrationError(e.to_string()))?;

        Ok(Self { pool })
    }

    async fn get_connection(&self) -> Result<bb8::PooledConnection<'_, AsyncDieselConnectionManager<AsyncSqliteConnection>>, PersistenceError> {
        self.pool.get().await.map_err(|e| {
            PersistenceError::ConnectionError(diesel::result::Error::DatabaseError(
                diesel::result::DatabaseErrorKind::__Unknown,
                Box::new(format!("Failed to get connection: {}", e))
            ))
        })
    }
}

#[async_trait]
impl PersistenceService for SqlitePersistenceService {
    async fn load_app_state(&self) -> Result<AppState, PersistenceError> {
        let mut conn = self.get_connection().await?;

        // Load all entities in parallel
        let (tools, kbs, pipelines, pipeline_runs, schedules, flows, settings, recent_metrics) = tokio::try_join!(
            self.load_tools(&mut conn),
            self.load_kbs(&mut conn),
            self.load_pipelines(&mut conn),
            self.load_pipeline_runs(&mut conn),
            self.load_schedules(&mut conn),
            self.load_flows(&mut conn),
            self.load_settings_internal(&mut conn),
            self.load_recent_metrics(&mut conn, 1000) // Load last 1000 metrics
        )?;

        Ok(AppState {
            tools,
            kb_packs: kbs,
            pipelines,
            pipeline_runs,
            schedules,
            flows,
            settings,
            recent_logs: VecDeque::new(), // Logs are not persisted in MVP
            metrics: recent_metrics,
            loading_states: HashMap::new(),
            errors: HashMap::new(),
        })
    }

    async fn save_app_state(&self, state: &AppState) -> Result<(), PersistenceError> {
        let mut conn = self.get_connection().await?;

        // Use transaction for atomicity
        conn.transaction(|conn| async move {
            // Save all entities
            self.save_all_tools(conn, &state.tools).await?;
            self.save_all_kbs(conn, &state.kb_packs).await?;
            self.save_all_pipelines(conn, &state.pipelines).await?;
            self.save_all_pipeline_runs(conn, &state.pipeline_runs).await?;
            self.save_all_schedules(conn, &state.schedules).await?;
            self.save_all_flows(conn, &state.flows).await?;
            self.save_settings_internal(conn, &state.settings).await?;
            self.save_all_metrics(conn, &state.metrics).await?;

            Ok(())
        }).await
    }

    async fn save_tool(&self, tool: &Tool) -> Result<(), PersistenceError> {
        let mut conn = self.get_connection().await?;

        use crate::schema::tools::dsl::*;

        let tool_record = ToolRecord {
            id: tool.id.clone(),
            name: tool.name.clone(),
            description: tool.description.clone(),
            schema_json: serde_json::to_string(&tool.schema)?,
            endpoint_config: serde_json::to_string(&tool.endpoint_config)?,
            status: tool.status.to_string(),
            created_at: tool.created_at,
            updated_at: tool.updated_at,
        };

        diesel::insert_into(tools)
            .values(&tool_record)
            .on_conflict(id)
            .do_update()
            .set((
                name.eq(&tool_record.name),
                description.eq(&tool_record.description),
                schema_json.eq(&tool_record.schema_json),
                endpoint_config.eq(&tool_record.endpoint_config),
                status.eq(&tool_record.status),
                updated_at.eq(chrono::Utc::now()),
            ))
            .execute(&mut conn)
            .await?;

        Ok(())
    }

    async fn save_metric(&self, metric: &MetricValue) -> Result<(), PersistenceError> {
        let mut conn = self.get_connection().await?;

        use crate::schema::metrics::dsl::*;

        let metric_record = MetricRecord {
            name: metric.name.clone(),
            value: metric.value,
            labels_json: serde_json::to_string(&metric.labels)?,
            timestamp: metric.timestamp,
        };

        diesel::insert_into(metrics)
            .values(&metric_record)
            .execute(&mut conn)
            .await?;

        Ok(())
    }

    async fn save_event(&self, event: &PersistenceEvent) -> Result<(), PersistenceError> {
        let mut conn = self.get_connection().await?;

        use crate::schema::events::dsl::*;

        let event_record = EventRecord {
            event_type: event.event_type.clone(),
            component: event.component.clone(),
            event_data: serde_json::to_string(&event.event_data)?,
            timestamp: event.timestamp,
        };

        diesel::insert_into(events)
            .values(&event_record)
            .execute(&mut conn)
            .await?;

        Ok(())
    }

    async fn cleanup_old_metrics(&self, older_than: chrono::DateTime<chrono::Utc>) -> Result<(), PersistenceError> {
        let mut conn = self.get_connection().await?;

        use crate::schema::metrics::dsl::*;

        diesel::delete(metrics.filter(timestamp.lt(older_than)))
            .execute(&mut conn)
            .await?;

        Ok(())
    }

    async fn cleanup_completed_runs(&self, older_than: chrono::DateTime<chrono::Utc>) -> Result<(), PersistenceError> {
        let mut conn = self.get_connection().await?;

        use crate::schema::pipeline_runs::dsl::*;

        diesel::delete(pipeline_runs.filter(
            completed_at.is_not_null().and(completed_at.lt(older_than))
        ))
        .execute(&mut conn)
        .await?;

        Ok(())
    }

    async fn cleanup_resolved_errors(&self, older_than: chrono::DateTime<chrono::Utc>) -> Result<(), PersistenceError> {
        let mut conn = self.get_connection().await?;

        use crate::schema::errors::dsl::*;

        diesel::delete(errors.filter(
            resolved.eq(true).and(resolved_at.is_not_null()).and(resolved_at.lt(older_than))
        ))
        .execute(&mut conn)
        .await?;

        Ok(())
    }
}
```

### Database Records (Diesel Models)

```rust
use diesel::prelude::*;
use chrono::{DateTime, Utc};

#[derive(Queryable, Insertable, Selectable, Debug)]
#[diesel(table_name = tools)]
pub struct ToolRecord {
    pub id: String,
    pub name: String,
    pub description: Option<String>,
    pub schema_json: String,
    pub endpoint_config: String,
    pub status: String,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
}

#[derive(Queryable, Insertable, Selectable, Debug)]
#[diesel(table_name = knowledge_bases)]
pub struct KnowledgeBaseRecord {
    pub id: String,
    pub name: String,
    pub version: String,
    pub description: Option<String>,
    pub status: String,
    pub health: String,
    pub metadata_json: String,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
}

#[derive(Queryable, Insertable, Selectable, Debug)]
#[diesel(table_name = pipeline_runs)]
pub struct PipelineRunRecord {
    pub id: String,
    pub pipeline_id: String,
    pub status: String,
    pub started_at: DateTime<Utc>,
    pub completed_at: Option<DateTime<Utc>>,
    pub metrics_json: Option<String>,
    pub error_message: Option<String>,
}

#[derive(Queryable, Insertable, Selectable, Debug)]
#[diesel(table_name = metrics)]
pub struct MetricRecord {
    pub name: String,
    pub value: f64,
    pub labels_json: Option<String>,
    pub timestamp: DateTime<Utc>,
}

#[derive(Queryable, Insertable, Selectable, Debug)]
#[diesel(table_name = events)]
pub struct EventRecord {
    pub event_type: String,
    pub component: String,
    pub event_data: String,
    pub timestamp: DateTime<Utc>,
}

#[derive(Queryable, Insertable, Selectable, Debug)]
#[diesel(table_name = errors)]
pub struct ErrorRecord {
    pub id: String,
    pub component: String,
    pub error_type: String,
    pub message: String,
    pub recoverable: bool,
    pub resolved: bool,
    pub timestamp: DateTime<Utc>,
    pub resolved_at: Option<DateTime<Utc>>,
}
```

## Persistence Manager

### Integration with AppStateManager

```rust
use tokio::time::{interval, Duration};
use std::sync::Arc;

pub struct PersistenceManager {
    persistence_service: Arc<dyn PersistenceService>,
    state_manager: AppStateManager,
    save_interval: Duration,
}

impl PersistenceManager {
    pub fn new(
        persistence_service: Arc<dyn PersistenceService>,
        state_manager: AppStateManager,
        save_interval_seconds: u64,
    ) -> Self {
        Self {
            persistence_service,
            state_manager,
            save_interval: Duration::from_secs(save_interval_seconds),
        }
    }

    /// Initialize state from database
    pub async fn load_initial_state(&self) -> Result<(), PersistenceError> {
        let loaded_state = self.persistence_service.load_app_state().await?;

        self.state_manager.write(|state| {
            *state = loaded_state;
            ((), None) // No event needed for initial load
        })?;

        Ok(())
    }

    /// Start periodic save task
    pub async fn start_periodic_saves(&self) -> Result<(), PersistenceError> {
        let persistence_service = self.persistence_service.clone();
        let state_manager = self.state_manager.clone();
        let mut interval = interval(self.save_interval);

        tokio::spawn(async move {
            loop {
                interval.tick().await;

                // Get current state snapshot
                let state_snapshot = match state_manager.read(|state| state.clone()) {
                    Ok(state) => state,
                    Err(e) => {
                        eprintln!("Failed to read state for periodic save: {}", e);
                        continue;
                    }
                };

                // Save to database
                if let Err(e) = persistence_service.save_app_state(&state_snapshot).await {
                    eprintln!("Periodic save failed: {}", e);

                    // Set error state
                    let error = AppError {
                        id: uuid::Uuid::new_v4().to_string(),
                        component: "persistence".to_string(),
                        error_type: "save_failed".to_string(),
                        message: format!("Periodic save failed: {}", e),
                        timestamp: Utc::now(),
                        recoverable: true,
                    };

                    let _ = state_manager.set_error(error);
                } else {
                    // Clear any previous persistence errors
                    let _ = state_manager.clear_error("persistence");
                }
            }
        });

        Ok(())
    }

    /// Manual save operation
    pub async fn save_now(&self) -> Result<(), PersistenceError> {
        let state_snapshot = self.state_manager.read(|state| state.clone())?;
        self.persistence_service.save_app_state(&state_snapshot).await
    }

    /// Start cleanup task
    pub async fn start_cleanup_task(&self) -> Result<(), PersistenceError> {
        let persistence_service = self.persistence_service.clone();
        let mut cleanup_interval = interval(Duration::from_hours(6)); // Cleanup every 6 hours

        tokio::spawn(async move {
            loop {
                cleanup_interval.tick().await;

                let now = Utc::now();
                let metrics_cutoff = now - chrono::Duration::days(7);
                let runs_cutoff = now - chrono::Duration::days(30);
                let errors_cutoff = now - chrono::Duration::hours(24);

                // Cleanup old data
                let cleanup_results = tokio::join!(
                    persistence_service.cleanup_old_metrics(metrics_cutoff),
                    persistence_service.cleanup_completed_runs(runs_cutoff),
                    persistence_service.cleanup_resolved_errors(errors_cutoff)
                );

                for result in [cleanup_results.0, cleanup_results.1, cleanup_results.2] {
                    if let Err(e) = result {
                        eprintln!("Cleanup operation failed: {}", e);
                    }
                }
            }
        });

        Ok(())
    }
}
```

## Data Migration Strategy

### Migration System

```rust
use diesel_migrations::*;

pub struct MigrationManager {
    database_url: String,
}

impl MigrationManager {
    pub fn new(database_url: String) -> Self {
        Self { database_url }
    }

    pub fn run_pending_migrations(&self) -> Result<(), PersistenceError> {
        let mut conn = SqliteConnection::establish(&self.database_url)
            .map_err(PersistenceError::ConnectionError)?;

        conn.run_pending_migrations(MIGRATIONS)
            .map_err(|e| PersistenceError::MigrationError(e.to_string()))?;

        Ok(())
    }

    pub fn revert_last_migration(&self) -> Result<(), PersistenceError> {
        let mut conn = SqliteConnection::establish(&self.database_url)
            .map_err(PersistenceError::ConnectionError)?;

        conn.revert_last_migration(MIGRATIONS)
            .map_err(|e| PersistenceError::MigrationError(e.to_string()))?;

        Ok(())
    }
}
```

### Data Validation

```rust
impl SqlitePersistenceService {
    /// Validate data integrity on startup
    pub async fn validate_data_integrity(&self) -> Result<(), PersistenceError> {
        let mut conn = self.get_connection().await?;

        // Check foreign key constraints
        let constraint_violations: Vec<String> = diesel::sql_query("PRAGMA foreign_key_check")
            .load(&mut conn)
            .await?;

        if !constraint_violations.is_empty() {
            return Err(PersistenceError::IntegrityError(format!(
                "Foreign key constraint violations: {:?}",
                constraint_violations
            )));
        }

        // Check for orphaned records
        self.check_orphaned_pipeline_runs(&mut conn).await?;
        self.check_orphaned_schedules(&mut conn).await?;

        Ok(())
    }

    async fn check_orphaned_pipeline_runs(&self, conn: &mut AsyncSqliteConnection) -> Result<(), PersistenceError> {
        use crate::schema::pipeline_runs::dsl::*;

        let orphaned_count: i64 = pipeline_runs
            .filter(pipeline_id.ne_all(
                crate::schema::pipelines::table.select(crate::schema::pipelines::id)
            ))
            .count()
            .get_result(conn)
            .await?;

        if orphaned_count > 0 {
            return Err(PersistenceError::IntegrityError(format!(
                "Found {} orphaned pipeline runs",
                orphaned_count
            )));
        }

        Ok(())
    }
}
```

## Error Handling and Recovery

### Backup and Recovery

```rust
impl SqlitePersistenceService {
    /// Create backup of database
    pub async fn create_backup(&self, backup_path: &str) -> Result<(), PersistenceError> {
        let mut conn = self.get_connection().await?;

        // SQLite backup using VACUUM INTO
        diesel::sql_query(&format!("VACUUM INTO '{}'", backup_path))
            .execute(&mut conn)
            .await
            .map_err(PersistenceError::ConnectionError)?;

        Ok(())
    }

    /// Restore from backup
    pub async fn restore_from_backup(&self, backup_path: &str) -> Result<(), PersistenceError> {
        // This would typically involve:
        // 1. Stopping all connections
        // 2. Copying backup file over current database
        // 3. Reinitializing connection pool
        // 4. Running integrity checks

        // For MVP, we'll implement a simple file copy approach
        std::fs::copy(backup_path, &self.get_database_path()?)
            .map_err(|e| PersistenceError::IntegrityError(format!("Backup restore failed: {}", e)))?;

        // Validate after restore
        self.validate_data_integrity().await?;

        Ok(())
    }

    fn get_database_path(&self) -> Result<String, PersistenceError> {
        // Extract path from connection URL
        Ok("data/app_meta.db".to_string()) // Simplified for MVP
    }
}

/// Recovery strategies for different error types
impl PersistenceManager {
    pub async fn recover_from_error(&self, error: &PersistenceError) -> Result<(), PersistenceError> {
        match error {
            PersistenceError::ConnectionError(_) => {
                // Attempt to recreate connection pool
                self.reinitialize_connections().await
            }
            PersistenceError::IntegrityError(_) => {
                // Load last known good backup
                self.restore_from_last_backup().await
            }
            PersistenceError::MigrationError(_) => {
                // Revert to previous migration state
                self.revert_migrations().await
            }
            _ => Ok(()), // Other errors don't require special recovery
        }
    }

    async fn reinitialize_connections(&self) -> Result<(), PersistenceError> {
        // Implementation would recreate the connection pool
        // For MVP, we'll return OK as the pool handles reconnections automatically
        Ok(())
    }

    async fn restore_from_last_backup(&self) -> Result<(), PersistenceError> {
        // Find most recent backup file
        let backup_path = self.find_latest_backup()?;

        // Restore from backup
        if let Some(backup) = backup_path {
            self.persistence_service.restore_from_backup(&backup).await?;

            // Reload state from restored database
            self.load_initial_state().await?;
        }

        Ok(())
    }

    fn find_latest_backup(&self) -> Result<Option<String>, PersistenceError> {
        // Implementation to find latest backup file
        // For MVP, return None (no backup found)
        Ok(None)
    }
}
```

## Testing Strategy

### Unit Tests

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::NamedTempFile;

    async fn create_test_persistence_service() -> SqlitePersistenceService {
        let temp_file = NamedTempFile::new().unwrap();
        let database_url = format!("file:{}", temp_file.path().to_str().unwrap());

        SqlitePersistenceService::new(&database_url).await.unwrap()
    }

    #[tokio::test]
    async fn test_tool_crud_operations() {
        let service = create_test_persistence_service().await;

        let tool = Tool {
            id: "test_tool".to_string(),
            name: "Test Tool".to_string(),
            description: Some("A test tool".to_string()),
            schema: serde_json::json!({"type": "object"}),
            endpoint_config: EndpointConfig::default(),
            status: ToolStatus::Active,
            created_at: Utc::now(),
            updated_at: Utc::now(),
        };

        // Test save
        service.save_tool(&tool).await.unwrap();

        // Test load
        let loaded_state = service.load_app_state().await.unwrap();
        assert_eq!(loaded_state.tools.len(), 1);
        assert_eq!(loaded_state.tools.get("test_tool").unwrap().name, "Test Tool");

        // Test delete
        service.delete_tool("test_tool").await.unwrap();
        let loaded_state = service.load_app_state().await.unwrap();
        assert_eq!(loaded_state.tools.len(), 0);
    }

    #[tokio::test]
    async fn test_periodic_save_and_load() {
        let service = Arc::new(create_test_persistence_service().await);
        let state_manager = AppStateManager::new();
        let persistence_manager = PersistenceManager::new(
            service,
            state_manager.clone(),
            1, // 1 second interval for test
        );

        // Load initial state (should be empty)
        persistence_manager.load_initial_state().await.unwrap();

        // Add some data to state
        let kb = KnowledgeBase {
            id: "test_kb".to_string(),
            name: "Test KB".to_string(),
            // ... other fields
        };
        state_manager.upsert_kb(kb).unwrap();

        // Manual save
        persistence_manager.save_now().await.unwrap();

        // Create new state manager and load
        let new_state_manager = AppStateManager::new();
        let new_persistence_manager = PersistenceManager::new(
            persistence_manager.persistence_service.clone(),
            new_state_manager.clone(),
            60,
        );

        new_persistence_manager.load_initial_state().await.unwrap();

        // Verify data was persisted and loaded
        let kb_state = new_state_manager.get_kb_state().unwrap();
        assert_eq!(kb_state.len(), 1);
        assert_eq!(kb_state.get("test_kb").unwrap().name, "Test KB");
    }

    #[tokio::test]
    async fn test_cleanup_operations() {
        let service = create_test_persistence_service().await;

        // Add old metrics
        let old_metric = MetricValue {
            name: "old_metric".to_string(),
            value: 1.0,
            timestamp: Utc::now() - chrono::Duration::days(10),
            labels: HashMap::new(),
        };
        service.save_metric(&old_metric).await.unwrap();

        // Add recent metric
        let recent_metric = MetricValue {
            name: "recent_metric".to_string(),
            value: 2.0,
            timestamp: Utc::now(),
            labels: HashMap::new(),
        };
        service.save_metric(&recent_metric).await.unwrap();

        // Cleanup metrics older than 5 days
        let cutoff = Utc::now() - chrono::Duration::days(5);
        service.cleanup_old_metrics(cutoff).await.unwrap();

        // Verify only recent metric remains
        let state = service.load_app_state().await.unwrap();
        assert_eq!(state.metrics.len(), 1);
        assert!(state.metrics.contains_key("recent_metric"));
    }

    #[tokio::test]
    async fn test_data_integrity_validation() {
        let service = create_test_persistence_service().await;

        // This would test foreign key constraints, orphaned records, etc.
        // For now, just verify the validation runs without error
        service.validate_data_integrity().await.unwrap();
    }
}
```

## Performance Optimization

### Connection Pooling
- Use bb8 connection pool with configurable size (default: 10 connections)
- Connection timeout: 30 seconds
- Idle timeout: 10 minutes

### Query Optimization
- Use prepared statements via Diesel for all queries
- Implement proper indexing for common query patterns
- Use async operations to avoid blocking

### Batch Operations
```rust
impl SqlitePersistenceService {
    /// Batch save multiple entities in single transaction
    pub async fn batch_save_metrics(&self, metrics: &[MetricValue]) -> Result<(), PersistenceError> {
        let mut conn = self.get_connection().await?;

        conn.transaction(|conn| async move {
            for metric in metrics {
                self.save_metric_internal(conn, metric).await?;
            }
            Ok(())
        }).await
    }
}
```

## Configuration

### Database Configuration
```toml
[persistence]
database_url = "data/app_meta.db"
pool_size = 10
connection_timeout_seconds = 30
save_interval_seconds = 30
cleanup_interval_hours = 6

[retention]
metrics_retention_days = 7
completed_runs_retention_days = 30
resolved_errors_retention_hours = 24
```

## Future Upgrade Path

### Event Sourcing Migration
The current schema includes an `events` table that prepares for event sourcing:

1. **Split Database**: Move to separate `events.db` for event storage
2. **Event Replay**: Implement state reconstruction from event log
3. **Snapshots**: Periodic state snapshots for performance
4. **WAL Mode**: Enable Write-Ahead Logging for better concurrency

### Performance Enhancements
1. **Async WAL**: Enable WAL mode for better write concurrency
2. **Read Replicas**: Add read-only connections for queries
3. **Caching Layer**: Add Redis/in-memory cache for frequently accessed data
4. **Partitioning**: Implement table partitioning for large datasets

## Implementation Priority

1. **Database Schema** - Create migrations and core table structure
2. **Basic CRUD Operations** - Implement save/load for all entity types
3. **Connection Pool** - Set up async connection pooling with bb8
4. **Periodic Persistence** - Implement periodic save and load operations
5. **Data Validation** - Add integrity checks and validation
6. **Cleanup Tasks** - Implement data retention and cleanup
7. **Error Recovery** - Add backup/restore and error recovery
8. **Testing** - Comprehensive test coverage for all operations

## Success Criteria

- [ ] All AppState entities can be persisted to and loaded from SQLite
- [ ] Periodic save/load operations work reliably (30-second intervals)
- [ ] Data integrity validation catches common errors
- [ ] Cleanup operations maintain database size within reasonable bounds
- [ ] Connection pooling provides stable performance under load
- [ ] Backup and restore operations work correctly
- [ ] >90% test coverage for persistence operations
- [ ] Integration with AppStateManager is seamless and thread-safe
# 2.1.2 Versioning System Specification

**Phase:** 2.1 KB Data Model & API
**Component:** Versioning System
**Priority:** HIGH
**Dependencies:** 2.1.1 KB Schema, 1.1.1 SQLite Setup, 1.1.2 LanceDB Integration

## Overview

Implement KB versioning with atomic promotion, zero-copy operations via symlinks, rollback capabilities, and epoch-based garbage collection for efficient storage management.

## Requirements

### Functional Requirements

#### FR-2.1.2.1 Atomic Version Promotion
- Support zero-copy promotion from staging to active versions via filesystem symlinks
- Ensure atomic switchover with no service interruption during promotion
- Validate version integrity before promotion (checksum validation)
- Support promotion rollback if validation fails
- Maintain promotion audit log with timestamps and user context

#### FR-2.1.2.2 Version Rollback
- Enable rollback to any previous version within retention policy
- Support selective rollback (document-level, collection-level)
- Preserve rollback history and reasoning
- Validate rollback target version integrity
- Ensure data consistency after rollback operations

#### FR-2.1.2.3 Epoch-based Garbage Collection
- Implement generation-based cleanup of obsolete versions
- Support configurable retention policies (time-based, count-based)
- Perform background garbage collection without service interruption
- Track version dependencies to prevent premature cleanup
- Provide manual cleanup triggers for storage management

#### FR-2.1.2.4 Version Metadata Management
- Store version creation timestamps, checksums, and size metrics
- Track version relationships (parent/child, branching, merging)
- Maintain version-specific configuration snapshots
- Support version tagging and annotation
- Store version performance metrics and quality scores

#### FR-2.1.2.5 Zero-Copy Operations
- Use filesystem symlinks for instant version switching
- Implement copy-on-write semantics for modified content
- Support hard links for immutable content sharing
- Minimize disk space usage through deduplication
- Ensure symlink integrity and resolution

### Non-Functional Requirements

#### NFR-2.1.2.1 Performance
- Version promotion must complete within 1 second regardless of data size
- Rollback operations must complete within 5 seconds for collections <1GB
- Garbage collection must not impact active operations (background only)
- Version listing queries must complete within 100ms

#### NFR-2.1.2.2 Storage Efficiency
- Storage overhead for versioning must not exceed 10% of active data
- Deduplication must achieve >90% efficiency for unchanged content
- Compressed deltas must achieve >70% size reduction
- Symlink operations must be atomic and filesystem-safe

#### NFR-2.1.2.3 Reliability
- Version operations must be fully ACID compliant
- Recovery procedures must handle interrupted operations
- Version integrity must be continuously validated
- Concurrent version operations must be safely serialized

## Technical Specification

### Directory Structure

```
kb_data/
├── collections/
│   └── {collection_id}/
│       ├── active -> versions/v{current}/  # Symlink to active version
│       ├── staging/                        # Staging area for new versions
│       ├── versions/
│       │   ├── v1/
│       │   │   ├── documents/
│       │   │   ├── chunks/
│       │   │   ├── vectors.lance/          # LanceDB data
│       │   │   ├── bm25.index             # BM25 index files
│       │   │   └── manifest.json          # Version metadata
│       │   ├── v2/
│       │   └── v{n}/
│       └── metadata/
│           ├── versions.db                 # Version history SQLite
│           ├── retention_policy.json      # GC configuration
│           └── audit.log                  # Version operations log
└── epochs/
    ├── current_epoch                       # Current epoch marker
    └── {epoch_id}/                        # Epoch-based GC tracking
```

### Version Manifest Schema

```json
{
  "version": 42,
  "collection_id": "kb_docs_v1",
  "created_at": "2025-09-17T10:30:00Z",
  "parent_version": 41,
  "checksum": "sha256:abc123...",
  "size_bytes": 1048576,
  "document_count": 150,
  "chunk_count": 15000,
  "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
  "embedding_config": {
    "model_version": "1.0.0",
    "chunk_size": 512,
    "overlap": 50
  },
  "quality_metrics": {
    "recall_at_10": 0.95,
    "precision_at_10": 0.88,
    "average_score": 0.92
  },
  "files": {
    "documents": ["doc_001.json", "doc_002.json"],
    "chunks": ["chunks_000.parquet", "chunks_001.parquet"],
    "vectors": "vectors.lance",
    "bm25_index": "bm25.index"
  },
  "delta_from": {
    "version": 41,
    "added_documents": ["doc_003.json"],
    "removed_documents": [],
    "modified_documents": ["doc_001.json"],
    "delta_size_bytes": 102400
  }
}
```

### Rust Implementation

```rust
use serde::{Deserialize, Serialize};
use std::path::{Path, PathBuf};
use chrono::{DateTime, Utc};
use sha2::{Sha256, Digest};
use tokio::fs;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VersionManager {
    base_path: PathBuf,
    retention_policy: RetentionPolicy,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RetentionPolicy {
    max_versions: usize,
    max_age_days: u32,
    min_versions_to_keep: usize,
    cleanup_interval_hours: u32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Version {
    pub version: u32,
    pub collection_id: String,
    pub created_at: DateTime<Utc>,
    pub parent_version: Option<u32>,
    pub checksum: String,
    pub size_bytes: u64,
    pub document_count: u32,
    pub chunk_count: u32,
    pub embedding_model: String,
    pub embedding_config: serde_json::Value,
    pub quality_metrics: QualityMetrics,
    pub files: VersionFiles,
    pub delta_from: Option<DeltaInfo>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QualityMetrics {
    pub recall_at_10: f64,
    pub precision_at_10: f64,
    pub average_score: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VersionFiles {
    pub documents: Vec<String>,
    pub chunks: Vec<String>,
    pub vectors: String,
    pub bm25_index: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DeltaInfo {
    pub version: u32,
    pub added_documents: Vec<String>,
    pub removed_documents: Vec<String>,
    pub modified_documents: Vec<String>,
    pub delta_size_bytes: u64,
}

impl VersionManager {
    pub fn new(base_path: PathBuf, retention_policy: RetentionPolicy) -> Self {
        Self {
            base_path,
            retention_policy,
        }
    }

    pub async fn create_version(
        &self,
        collection_id: &str,
        parent_version: Option<u32>,
    ) -> Result<u32, VersionError> {
        // Implementation for creating new version
        todo!()
    }

    pub async fn promote_version(
        &self,
        collection_id: &str,
        version: u32,
    ) -> Result<(), VersionError> {
        let collection_path = self.base_path.join("collections").join(collection_id);
        let version_path = collection_path.join("versions").join(format!("v{}", version));
        let active_link = collection_path.join("active");

        // Validate version integrity
        self.validate_version_integrity(&version_path).await?;

        // Atomic symlink update
        let temp_link = collection_path.join("active.tmp");

        #[cfg(unix)]
        {
            fs::symlink(&version_path, &temp_link).await?;
            fs::rename(&temp_link, &active_link).await?;
        }

        #[cfg(windows)]
        {
            // Windows requires different handling for directory symlinks
            if active_link.exists() {
                fs::remove_dir(&active_link).await?;
            }
            std::os::windows::fs::symlink_dir(&version_path, &active_link)?;
        }

        Ok(())
    }

    pub async fn rollback_to_version(
        &self,
        collection_id: &str,
        target_version: u32,
    ) -> Result<(), VersionError> {
        // Validate target version exists and is valid
        let version_path = self.base_path
            .join("collections")
            .join(collection_id)
            .join("versions")
            .join(format!("v{}", target_version));

        if !version_path.exists() {
            return Err(VersionError::VersionNotFound(target_version));
        }

        // Validate version integrity before rollback
        self.validate_version_integrity(&version_path).await?;

        // Log rollback operation
        self.log_operation(collection_id, VersionOperation::Rollback {
            from_version: self.get_active_version(collection_id).await?,
            to_version: target_version,
        }).await?;

        // Perform atomic promotion to target version
        self.promote_version(collection_id, target_version).await?;

        Ok(())
    }

    pub async fn garbage_collect(&self) -> Result<GarbageCollectionResult, VersionError> {
        let mut result = GarbageCollectionResult::default();

        for collection_dir in fs::read_dir(self.base_path.join("collections")).await? {
            let collection_dir = collection_dir?;
            if collection_dir.file_type().await?.is_dir() {
                let collection_id = collection_dir.file_name().to_string_lossy().to_string();
                let collection_result = self.gc_collection(&collection_id).await?;
                result.merge(collection_result);
            }
        }

        Ok(result)
    }

    async fn validate_version_integrity(&self, version_path: &Path) -> Result<(), VersionError> {
        let manifest_path = version_path.join("manifest.json");
        let manifest_content = fs::read_to_string(&manifest_path).await?;
        let manifest: Version = serde_json::from_str(&manifest_content)?;

        // Validate checksum
        let calculated_checksum = self.calculate_version_checksum(version_path).await?;
        if calculated_checksum != manifest.checksum {
            return Err(VersionError::ChecksumMismatch {
                expected: manifest.checksum,
                actual: calculated_checksum,
            });
        }

        // Validate file existence
        for file in &manifest.files.documents {
            let file_path = version_path.join("documents").join(file);
            if !file_path.exists() {
                return Err(VersionError::MissingFile(file.clone()));
            }
        }

        Ok(())
    }

    async fn calculate_version_checksum(&self, version_path: &Path) -> Result<String, VersionError> {
        let mut hasher = Sha256::new();

        // Hash all files in deterministic order
        let mut file_paths = Vec::new();
        self.collect_files_recursive(version_path, &mut file_paths).await?;
        file_paths.sort();

        for file_path in file_paths {
            let content = fs::read(&file_path).await?;
            hasher.update(&content);
        }

        Ok(format!("sha256:{:x}", hasher.finalize()))
    }

    async fn collect_files_recursive(
        &self,
        dir: &Path,
        files: &mut Vec<PathBuf>,
    ) -> Result<(), VersionError> {
        let mut entries = fs::read_dir(dir).await?;
        while let Some(entry) = entries.next_entry().await? {
            let path = entry.path();
            if path.is_file() {
                files.push(path);
            } else if path.is_dir() {
                self.collect_files_recursive(&path, files).await?;
            }
        }
        Ok(())
    }

    async fn gc_collection(&self, collection_id: &str) -> Result<GarbageCollectionResult, VersionError> {
        let collection_path = self.base_path.join("collections").join(collection_id);
        let versions_path = collection_path.join("versions");

        let active_version = self.get_active_version(collection_id).await?;
        let versions = self.list_versions(collection_id).await?;

        let mut to_delete = Vec::new();
        let now = Utc::now();

        // Apply retention policy
        for version in versions {
            let should_delete = version.version != active_version
                && to_delete.len() + self.retention_policy.min_versions_to_keep < versions.len()
                && (to_delete.len() >= self.retention_policy.max_versions
                    || (now - version.created_at).num_days() > self.retention_policy.max_age_days as i64);

            if should_delete {
                to_delete.push(version);
            }
        }

        let mut result = GarbageCollectionResult::default();
        for version in to_delete {
            let version_path = versions_path.join(format!("v{}", version.version));
            let size = self.calculate_directory_size(&version_path).await?;

            fs::remove_dir_all(&version_path).await?;
            result.deleted_versions += 1;
            result.freed_bytes += size;
        }

        Ok(result)
    }

    async fn get_active_version(&self, collection_id: &str) -> Result<u32, VersionError> {
        let active_path = self.base_path.join("collections").join(collection_id).join("active");
        let target = fs::read_link(&active_path).await?;
        let version_str = target.file_name()
            .and_then(|n| n.to_str())
            .and_then(|s| s.strip_prefix("v"))
            .ok_or(VersionError::InvalidSymlink)?;

        version_str.parse().map_err(|_| VersionError::InvalidVersion)
    }

    async fn list_versions(&self, collection_id: &str) -> Result<Vec<Version>, VersionError> {
        let versions_path = self.base_path.join("collections").join(collection_id).join("versions");
        let mut versions = Vec::new();

        let mut entries = fs::read_dir(&versions_path).await?;
        while let Some(entry) = entries.next_entry().await? {
            if entry.file_type().await?.is_dir() {
                let manifest_path = entry.path().join("manifest.json");
                if manifest_path.exists() {
                    let content = fs::read_to_string(&manifest_path).await?;
                    let version: Version = serde_json::from_str(&content)?;
                    versions.push(version);
                }
            }
        }

        versions.sort_by_key(|v| v.version);
        Ok(versions)
    }

    async fn calculate_directory_size(&self, dir: &Path) -> Result<u64, VersionError> {
        let mut total_size = 0;
        let mut entries = fs::read_dir(dir).await?;

        while let Some(entry) = entries.next_entry().await? {
            let metadata = entry.metadata().await?;
            if metadata.is_file() {
                total_size += metadata.len();
            } else if metadata.is_dir() {
                total_size += self.calculate_directory_size(&entry.path()).await?;
            }
        }

        Ok(total_size)
    }

    async fn log_operation(
        &self,
        collection_id: &str,
        operation: VersionOperation,
    ) -> Result<(), VersionError> {
        let log_entry = VersionLogEntry {
            timestamp: Utc::now(),
            collection_id: collection_id.to_string(),
            operation,
        };

        let log_path = self.base_path
            .join("collections")
            .join(collection_id)
            .join("metadata")
            .join("audit.log");

        let log_line = format!("{}\n", serde_json::to_string(&log_entry)?);
        fs::write(&log_path, log_line).await?;

        Ok(())
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum VersionOperation {
    Create { version: u32 },
    Promote { version: u32 },
    Rollback { from_version: u32, to_version: u32 },
    Delete { version: u32 },
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VersionLogEntry {
    pub timestamp: DateTime<Utc>,
    pub collection_id: String,
    pub operation: VersionOperation,
}

#[derive(Debug, Default)]
pub struct GarbageCollectionResult {
    pub deleted_versions: u32,
    pub freed_bytes: u64,
}

impl GarbageCollectionResult {
    fn merge(&mut self, other: GarbageCollectionResult) {
        self.deleted_versions += other.deleted_versions;
        self.freed_bytes += other.freed_bytes;
    }
}

#[derive(Debug, thiserror::Error)]
pub enum VersionError {
    #[error("Version {0} not found")]
    VersionNotFound(u32),

    #[error("Checksum mismatch: expected {expected}, got {actual}")]
    ChecksumMismatch { expected: String, actual: String },

    #[error("Missing file: {0}")]
    MissingFile(String),

    #[error("Invalid symlink target")]
    InvalidSymlink,

    #[error("Invalid version number")]
    InvalidVersion,

    #[error("IO error: {0}")]
    Io(#[from] std::io::Error),

    #[error("JSON error: {0}")]
    Json(#[from] serde_json::Error),
}
```

## Implementation Details

### Atomic Promotion Strategy
- Use filesystem symlinks for instant version switching
- Implement two-phase promotion: validate → atomically switch symlink
- Support rollback by switching symlink back to previous version
- Maintain promotion audit log for debugging and compliance

### Zero-Copy Implementation
- Leverage filesystem hard links for immutable content sharing
- Use copy-on-write semantics for modified content only
- Implement symlink integrity checking and resolution
- Support cross-platform symlink operations (Unix/Windows)

### Garbage Collection Algorithm
- Use epoch-based tracking to prevent premature cleanup
- Implement background garbage collection with configurable scheduling
- Support manual cleanup triggers for storage management
- Preserve version dependencies and active references

## Testing Strategy

### Unit Tests
- Test version creation, promotion, and rollback operations
- Verify symlink integrity and atomic operations
- Test garbage collection algorithms with various retention policies
- Validate checksum calculation and verification

### Integration Tests
- Test version operations with real filesystem operations
- Verify concurrent access patterns and safety
- Test cross-platform symlink compatibility
- Validate performance with large version histories

### Performance Tests
- Benchmark promotion speed with varying data sizes
- Test garbage collection performance impact
- Measure symlink resolution overhead
- Validate storage efficiency with realistic datasets

## Acceptance Criteria

### AC-2.1.2.1 Atomic Promotion
- [ ] Version promotion completes within 1 second
- [ ] Symlink operations are atomic and safe
- [ ] Promotion validation prevents corrupted versions
- [ ] Rollback capability works for all scenarios

### AC-2.1.2.2 Zero-Copy Operations
- [ ] Symlink-based version switching implemented
- [ ] Storage deduplication achieves >90% efficiency
- [ ] Cross-platform compatibility verified
- [ ] Hard link support for immutable content

### AC-2.1.2.3 Garbage Collection
- [ ] Background GC runs without service impact
- [ ] Retention policies configurable and enforced
- [ ] Manual cleanup triggers work correctly
- [ ] Version dependencies prevent premature deletion

### AC-2.1.2.4 Performance Requirements
- [ ] All operations meet specified timeframes
- [ ] Storage overhead stays within 10% limit
- [ ] Concurrent operations safely serialized
- [ ] Version listing queries under 100ms